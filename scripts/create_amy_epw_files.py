import os
import glob
import numpy as np
import pandas as pd
import argparse
import diyepw
import math

# Set path to outputs produced by this script.
create_out_path  = os.path.join('..', 'outputs', 'create_amy_epw_files_output')

# Set path to where new EPW files should be saved.
amy_epw_file_out_path = os.path.join(create_out_path, 'epw')
if not os.path.exists(amy_epw_file_out_path):
    os.mkdir(amy_epw_file_out_path)

# Provide the path to the list of WMO stations for which new AMY EPW files should be created.
path_to_station_list = os.path.join('..', 'outputs', 'analyze_noaa_data_output', 'files_to_convert.csv')

epw_file_violations_path = os.path.join(create_out_path, 'epw_validation_errors.csv')
errors_path = os.path.join(create_out_path, 'errors.csv')

parser = argparse.ArgumentParser(
    description=f"""
        Generate epw files based on the files generated by unpack_noaa_data.py and analyze_noaa_data.py, which must
        be called prior to this script. The generated files will be written to {amy_epw_file_out_path}
    """
)
parser.add_argument('--max-records-to-interpolate',
                    default=6,
                    type=int,
                    help="""The maximum number of consecutive records to interpolate. See the documentation of the
                            pandas.DataFrame.interpolate() method's "limit" argument for more details. Basically,
                            if a sequence of fields up to the length defined by this argument are missing, those 
                            missing values will be interpolated linearly using the values of the fields immediately 
                            preceding and following the missing field(s). If a sequence of fields is longer than this
                            limit, then those fields' values will be imputed instead (see --max-records-to-impute)
                            """
                    )

parser.add_argument('--max-records-to-impute',
                    default=48,
                    type=int,
                    help=f"""The maximum number of records to impute. For groups of missing records larger than the
                            limit set by --max-records-to-interpolate, we replace the missing values using the
                            average of the values two weeks prior and two weeks after the missing value. However, if
                            there are more missing records after interpolation than this limit (i.e. if a group of
                            missing records is larger than --max-records-to-interpolate PLUS --max-records-to-impute)
                            then the file will be discarded. Information about discarded files can be found in
                            {errors_path}""")
args = parser.parse_args()

# Read in list of AMY files that should be used to create EPW files.
amy_file_list = pd.read_csv(path_to_station_list)
amy_file_list = amy_file_list[amy_file_list.columns[0]]

epw_rule_violations_found = False

# Truncate the contents of the EPW violations file so that it only contains entries from this run
with open(epw_file_violations_path, 'w'):
    pass # We don't have to do anything but open the file, because 'w' mode truncates the file contents

# Initialize the df to hold paths of AMY files that could not be converted to an EPW.
amy_files_with_errors = pd.DataFrame(columns=['file', 'error'])

# Iterate through stations in the list.
for idx, amy_file_path in enumerate(amy_file_list, start=1):

    print("Processing", amy_file_path, "(", idx, "/", len(amy_file_list), ")")

    try:
        amy_file_name = os.path.basename(amy_file_path)
        amy_file_name_without_ext = os.path.splitext(amy_file_name)[0]

        # Get the station number and year from the AMY file name
        wmo_station_id = amy_file_name_without_ext.split("-")[0]
        year = int(amy_file_name_without_ext.split("-")[-1])

        # Get path to the TMY EPW file corresponding to that station.
        tmy3_epw_file_path = glob.glob(
            os.path.join('..', 'inputs', 'Energy_Plus_TMY3_EPW', f'*.{wmo_station_id}_TMY3.epw')
        )[0]

        # Read in the NOAA AMY file for the station
        amy_df = pd.read_csv(amy_file_path, delim_whitespace=True, header=None)
        amy_df = diyepw.clean_noaa_df(amy_df)

        # Save the first timestamp for that year; we will need it later after we time-shift so that we can trim
        # the data to only values after this time
        start_timestamp = amy_df.index[0]

        # Read in the corresponding TMY3 EPW file.
        tmy = diyepw.Meteorology.from_tmy3_file(tmy3_epw_file_path)

        # Identify the time zone shift as an integer.
        tz_shift = tmy.timezone_gmt_offset

        # Identify the number of time steps to be obtained from the subsequent year's NOAA file.
        abs_time_steps = math.ceil(abs(tz_shift))

        # Identify the name of the subsequent year's NOAA file.
        year_s_string = str(int(year) + 1)
        glob_string = os.path.abspath(
            os.path.join('..', 'inputs', 'NOAA_ISD_Lite_Raw', '**', wmo_station_id + '*' + year_s_string + '*')
        )
        noaa_amy_s_info_path = glob.glob(glob_string)
        if len(noaa_amy_s_info_path) == 0:
            raise Exception("Couldn't load subsequent year's data: no file was found matching '" + glob_string + "'")
        noaa_amy_s_info_path = noaa_amy_s_info_path[0]

        # Read in the NOAA AMY file for the station for the subsequent year.
        amy_df_s = pd.read_csv(noaa_amy_s_info_path,
                               delim_whitespace=True,
                               header=None)

        # Clean the NOAA AMY data frame for the subsequent year.
        amy_df_s = diyepw.clean_noaa_df(amy_df_s)

        # Grab the appropriate number of time steps for the subsequent year.
        amy_df_s = amy_df_s.head(abs_time_steps)

        # Append the NOAA dataframe for the subsequent year to the dataframe for the year of interest.
        amy_df = amy_df.append(amy_df_s)

        # Shift the timestamp (index) to match the time zone of the WMO station.
        amy_df = amy_df.shift(periods=tz_shift, freq='H')

        # Remove time steps that aren't applicable to the year of interest
        amy_df = amy_df[amy_df.index >= start_timestamp]

        diyepw.handle_missing_values(
            amy_df,
            step=pd.Timedelta("1h"),
            max_to_interpolate=args.max_records_to_interpolate,
            max_to_impute=args.max_records_to_impute,
            imputation_range=pd.Timedelta("2w"),
            imputation_step=pd.Timedelta("1d"),
            missing_values=[np.nan, -9999.]
        )

        # Initialize new column for station pressure (not strictly necessary)
        amy_df['Station_Pressure'] = None

        # Convert sea level pressure in NOAA df to atmospheric station pressure in Pa.
        for index in amy_df.index:
            stp = diyepw.convert_to_station_pressure(amy_df['Sea_Level_Pressure'][index], tmy.elevation)
            amy_df.loc[index, 'Station_Pressure'] = stp

        # Change observation values to the values taken from the AMY data
        tmy.set('year', year)
        tmy.set('Tdb', [i / 10 for i in amy_df['Air_Temperature']]) # Convert AMY value to degrees C
        tmy.set('Tdew', [i / 10 for i in amy_df['Dew_Point_Temperature']]) # Convert AMY value to degrees C
        tmy.set('Patm', amy_df['Station_Pressure'])
        tmy.set('Wdir', amy_df['Wind_Direction'])
        tmy.set('Wspeed', [i / 10 for i in amy_df['Wind_Speed']]) # Convert AMY value to m/sec

        # Check for violations of EPW file standards, and if any exist, append them to the violations file
        epw_rule_violations = tmy.validate_against_epw_rules()
        if len(epw_rule_violations) > 0:
            with open(epw_file_violations_path, 'a') as f:
                for violation in epw_rule_violations:
                    # If this is the first violation we've found, add a header row
                    if not epw_rule_violations_found:
                        f.write(",".join(list(violation) + ["file"]))
                        epw_rule_violations_found = True

                    # Convert the violation definition from a dict to a list of strings
                    violation = [str(i) for i in violation.values()]

                    # Add the AMY file name to the row to be written to the file
                    violation.insert(0, amy_file_path)

                    f.write(",".join(violation) + "\n")

        # Write new EPW file.
        tmy.write_epw(amy_epw_file_out_path)

    except Exception as e:
        amy_files_with_errors = amy_files_with_errors.append({"file": amy_file_path, "error": str(e)}, ignore_index=True)
        print('Problem processing: ' + amy_file_path + ': ' + str(e))

# Write CSV of any NOAA files that were not processed into an EPW file.
if not amy_files_with_errors.empty:
    # Set mode='a' so that the error is appended
    amy_files_with_errors.to_csv(errors_path, mode='a', index=False)
else:
    print('All files were converted to EPWs.')

# Write CSV of any files that have values that will fail the EPW maximum/minimum criteria.
if epw_rule_violations_found:
    print('Some files violate EPW validation rules. Check ' + epw_file_violations_path + ' for more information')
else:
    print('No files were found to have issues with EPW maximum or minimum values.')

print('All files are processed. See create_amy_files_output in the outputs directory for any issues.')
